---
title: Módulo 5
subtitle: Métodos no supervisados
format:
  clean-revealjs:
    self-contained: true
    theme: slides.scss
    touch: true
    slide-level: 2
author:
  - name: Eloy Alvarado Narváez
    orcid: 0000-0001-7522-2327
    email: eloy.alvarado@usm.cl
    affiliations: Universidad Técnica Federico Santa María
  - name: Esteban Salgado Valenzuela
    orcid: 0000-0002-7799-0044
    affiliations: Universidad Técnica Federico Santa María
date: 12/14/2024
lang: es
logo: images/logo_usm.png
bibliography: refs.bib
---

## Aprendizaje no supervisado
### No supervisado vs Supervisado

- Hemos visto modelos supervisados (ej: regresión, clasificación).
- En ese contexto se observan características $X_1,\ldots,X_p$ y una respuesta $Y$ para cada dato.
  + Se busca predecir $Y$ usando $X_1,\ldots,X_p$
- En el [aprendizaje no supervisado,]{.bg4} solo se observan las características $X_1,\ldots,X_p$.
  + No hay predicción.
- El objetivo es descubrir cosas interesantes de los datos.
  + ¿Se pueden visualizar los datos con sentido?
  + ¿Podemos descubrir subgrupos entre las variables u observaciones?

## Aprendizaje no supervisado
### No supervisado vs Supervisado

- El aprendizaje no supervisado es más subjetivo que el supervisado.
  + No hay un objetivo simple de análisis, como una predicción o respuesta.

- Usualmente, es más fácil obtener datos [sin etiqutar]{.alert} que etiqutados.
  + El etiquetado puede requerir intervención humana.

# Análsis de Componentes Principales{background-color="#40666e"}

## Análsis de Componentes Principales (PCA)

- [PCA]{.bg3} produce una representación de baja dimensión del conjunto de datos.
- Encuentra una secuencia de combinaciones lineales de las variables con [máxima varianza]{.alert} y [mutuamente no correlacionadas]{.alert}.
  + Puede producir variables alternativas para usar en problemas de aprendizaje supervisado.
  + También sirve como herramiente para la visualización de datos.

## Análsis de Componentes Principales (PCA)
### Primera Componente Principal 

- El [primer componente principal]{.bg4} de un conjunto de características $X_1,\ldots,X_p$ es la [combinación lineal normalizada]{.alert} de las características:
$$Z_1 = \phi_{11}X_1+\cdots+\phi_{p1}X_p$$
que maximiza la varianza.
  + [Normalizado]{.alert} significa que $\|\phi_1\|^2_2 = 1$, con $\phi_1 = (\phi_{11},\ldots,\phi_{p1})^\top.$
  + ¿Por qué normalizar?

## Análsis de Componentes Principales (PCA)
### Ejemplo

![](./images/mod5/fig1.png)

## Análsis de Componentes Principales (PCA)
### Cálculo de Componentes Principales

- Conjunto de datos $X$ de $n\times p$.
  + Se asumen [datos centrados]{.alert} (promedio de las columnas es $0$).
  + Simplifica los cálculos.
- Se busca la combinación lineal de las características
$$z_{i1} = \phi_{11}x_{i1} + \cdots + \phi_{p1}x_{ip}$$
que maximiza la varianza, sujeto a $\|\phi_1\|^2_2 = 1$.

- Como las columnas de $X$ tienen promedio $0$, también lo tiene $z_{i1}$ (independiente del valor de $\phi_1$).
  + La varianza de $z_{i1}$ puede escribirse $\frac{1}{n}\sum\limits_{i=1}^nz_{i1}^2.$

## Análsis de Componentes Principales (PCA)
### Cálculo de Componentes Principales

- Entonces el problema de encontrar el primer componente principal, consiste en resolver el problema

\begin{equation*}
\begin{array}{rrl}
\max\limits_{\phi_1} & \frac{1}{n}\sum\limits_{i=1}^n\left(\sum\limits_{j=1}^p\phi_{j1}x_{ij}\right)^2 &\\
\text{s.t.} & \sum\limits_{j=1}^p\phi_{j1}^2 &= 1
\end{array}
\end{equation*}

- Se puede resolver con descomposición de valores singulares (SVD). 
- $Z_1$ es el [primer componente principal]{.bg4} con [valores de realización]{.bg3} $z_{11},\ldots,z_{n1}$. 

# Métodos de Clustering{background-color="#40666e"}

## Métodos de Clustering