{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Módulo 4\n",
    "subtitle: Métodos de remuestreo\n",
    "author:\n",
    "  - name: Eloy Alvarado Narváez\n",
    "    orcid: 0000-0001-7522-2327\n",
    "    email: eloy.alvarado@usm.cl\n",
    "    affiliations: Universidad Técnica Federico Santa María\n",
    "  - name: Esteban Salgado Valenzuela\n",
    "    orcid: 0000-0002-7799-0044\n",
    "    affiliations: Universidad Técnica Federico Santa María\n",
    "date: 14/12/2024\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio exploraremos las técnicas de remuestreo tratadas en este capítulo. Ten en cuenta que algunos de los comandos utilizados aquí pueden tardar un tiempo en ejecutarse en tu computadora.\n",
    "\n",
    "Nuevamente, comenzaremos colocando nuestros imports en este nivel superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto de Validación\n",
    "\n",
    "En esta sección exploraremos el uso del enfoque de conjunto de validación para estimar las tasas de error en el conjunto de prueba derivadas de ajustar diversos modelos lineales al conjunto de datos `Auto`.\n",
    "\n",
    "Utilizaremos la función `train_test_split()` para dividir los datos en conjuntos de entrenamiento y validación. Dado que contamos con 392 observaciones, las separaremos en dos conjuntos iguales de 196 registros cada uno, empleando el argumento `test_size=196`. En general, es una buena práctica establecer una semilla aleatoria al realizar operaciones de este tipo, que incluyen un elemento de aleatoriedad, con el fin de poder reproducir exactamente los resultados más adelante. Para ello, fijamos la semilla del generador aleatorio con el argumento `random_state=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                         test_size=196,\n",
    "                                         random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ajustar un modelo de regresión lineal utilizando únicamente las observaciones correspondientes al conjunto de entrenamiento `Auto_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora empleamos el método `predict()` de `results`, evaluándolo sobre la matriz de modelo generada con el conjunto de datos de validación. Además, calculamos el MSE (Error Cuadrático Medio) de validación de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, nuestra estimación del MSE de validación para el ajuste de la regresión lineal es $23.62$.\n",
    "\n",
    "Asimismo, podemos estimar el error de validación para regresiones polinómicas de mayor orden. Primero proporcionamos una función, `evalMSE()`, que recibe como entrada una cadena que describe el modelo, así como los conjuntos de entrenamiento y prueba, y devuelve el MSE en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "\n",
    "   mm = MS(terms)\n",
    "   X_train = mm.fit_transform(train)\n",
    "   y_train = train[response]\n",
    "\n",
    "   X_test = mm.transform(test)\n",
    "   y_test = test[response]\n",
    "\n",
    "   results = sm.OLS(y_train, X_train).fit()\n",
    "   test_pred = results.predict(X_test)\n",
    "\n",
    "   return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilicemos esta función para estimar el MSE de validación empleando ajustes lineales, cuadráticos y cúbicos. Aquí recurrimos a la función `enumerate()`, la cual proporciona tanto los valores como los índices de los elementos mientras iteramos con un bucle for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas tasas de error son $23.62$, $18.76$ y $18.80$, respectivamente. Si optamos por una división distinta entre entrenamiento y validación, es de esperar que obtengamos errores algo diferentes en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando esta división de las observaciones entre el conjunto de entrenamiento y el de validación, observamos que las tasas de error en el conjunto de validación para los modelos con términos lineales, cuadráticos y cúbicos son $20.76$, $16.94$ y $16.97$, respectivamente.\n",
    "\n",
    "Estos resultados coinciden con nuestros hallazgos previos: un modelo que predice `mpg` empleando una función cuadrática del `horsepower` supera a uno que se basa únicamente en una función lineal, y no existe evidencia de mejora al emplear una función cúbica del `horsepower`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación Cruzada\n",
    "\n",
    "En teoría, la estimación mediante validación cruzada puede calcularse para cualquier modelo lineal generalizado (GLM). Sin embargo, en la práctica, la forma más sencilla de realizar validación cruzada en `Python` es utilizando `sklearn`, que presenta una interfaz o API diferente a la de `statsmodels`, el paquete que hemos estado utilizando para ajustar GLMs.\n",
    "\n",
    "Este es un problema que a menudo afrontan los científicos de datos: “Tengo una función que realiza la tarea $A$, y necesito alimentarla a otra que realiza la tarea $B$, de modo que pueda calcular $B(A(D))$, donde $D$ es mi conjunto de datos.” Cuando $A$ y $B$ no se comunican naturalmente entre sí, es necesario recurrir a un envoltorio (*wrapper*). En el paquete `ISLP` se proporciona la clase `sklearn_sm()`, que nos permite utilizar fácilmente las herramientas de validación cruzada de `sklearn` con modelos ajustados mediante `statsmodels`.\n",
    "\n",
    "La clase `sklearn_sm()` tiene como primer argumento un modelo de `statsmodels`. Puede además recibir dos argumentos opcionales: `model_str`, para especificar una fórmula, y `model_args`, que debe ser un diccionario con argumentos adicionales utilizados al ajustar el modelo. Por ejemplo, para ajustar un modelo de regresión logística es necesario especificar el argumento `family`. Esto se hace pasando `model_args={'family':sm.families.Binomial()}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.23151351792922"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los argumentos de la función `cross_validate()` son los siguientes: un objeto con los métodos `fit()`, `predict()` y `score()` adecuados, un arreglo de predictores `X` y una respuesta `Y`. Además, incluimos un argumento adicional `cv` en `cross_validate()`. Al especificar un entero $K$ da lugar a una validación cruzada de tipo $K$-fold. Aquí le hemos asignado un valor igual al número total de observaciones, lo que resulta en una validación cruzada *\"leave-one-out\"* (LOOCV). La función `cross_validate()` produce un diccionario con varios componentes; en este caso, simplemente nos interesa el valor de la métrica de prueba con validación cruzada (MSE), estimado en $24.23$.\n",
    "\n",
    "Podemos repetir este procedimiento para ajustes polinómicos cada vez más complejos. Para automatizar el proceso, utilizamos nuevamente un bucle for que itera sobre polinomios de grado 1 a 5, calcula el error de validación cruzada asociado y lo almacena en el elemento correspondiente del vector `cv_error`. La variable `d` en el bucle for corresponde al grado del polinomio. Comenzamos inicializando el vector. Esta ejecución puede tardar un par de segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443029, 19.03320648])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apreciamos una marcada disminución en el MSE estimado de prueba al pasar del ajuste lineal al cuadrático, pero no se observa una mejora clara al emplear polinomios de mayor grado.\n",
    "\n",
    "Arriba presentamos el método `outer()` de la función `np.power()`. El método `outer()` se aplica a una operación que requiere dos argumentos, como `add()`, `min()` o `power()`. Este método recibe dos arreglos como argumentos y produce un arreglo más grande donde la operación se aplica a cada par de elementos de dichos arreglos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo de validación cruzada anterior empleamos $K=n$, pero naturalmente también podemos utilizar $K<n$. El código es muy similar al anterior (y resulta significativamente más rápido). Aquí utilizaremos `KFold()` para particionar los datos en grupos aleatorios. Además, emplearemos `random_state` para establecer una semilla aleatoria e inicializaremos un vector `cv_error` donde almacenaremos los errores de validación cruzada correspondientes a los ajustes polinómicos de grado uno a cinco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848403, 19.13720065])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # usar mismos conjuntos en cada grado\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos que el tiempo de cómputo es mucho menor que el de LOOCV. (En principio, el tiempo de cómputo de LOOCV para un modelo lineal de mínimos cuadrados debería ser más rápido que para una validación cruzada de tipo $K$-fold, debido a la disponibilidad de la fórmula \n",
    "\n",
    "$$CV_{(n)} = \\frac{1}{n}\\sum\\limits_{i=1}^n\\left(\\frac{y_i-\\hat{y}_i}{1-h_i}\\right)^2$$\n",
    "\n",
    " para LOOCV; sin embargo, la función genérica `cross_validate()` no hace uso de dicha fórmula.) Aun así, seguimos sin encontrar evidencia de que el uso de términos cúbicos o de mayor grado genere un error de prueba menor que el simple ajuste cuadrático.\n",
    "\n",
    "La función `cross_validate()` es flexible y puede recibir distintos mecanismos de separación como argumento. Por ejemplo, se puede emplear la función `ShuffleSplit()` para implementar el enfoque de conjunto de validación con la misma facilidad que la $K$-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede estimar la variabilidad en el error de prueba ejecutando el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.61661706966988, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengamos en cuenta que esta desviación estándar no es una estimación válida de la variabilidad muestral de la media del error de prueba ni de los valores individuales, ya que las muestras de entrenamiento seleccionadas aleatoriamente se solapan y esto introduce correlaciones. Sin embargo, sí proporciona una idea de la variación de *Monte Carlo* que surge al escoger diferentes pliegues aleatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El Bootstrap\n",
    "\n",
    "Ilustraremos el uso de *bootstrap* con dos problemas.\n",
    "\n",
    "##### Estimando la Precisión de una Estadística de Interés\n",
    "\n",
    "Una de las grandes ventajas del enfoque bootstrap es que puede aplicarse en prácticamente cualquier situación, sin requerir complicados cálculos matemáticos. Aunque existen varias implementaciones de bootstrap en `Python`, su uso para estimar el error estándar es lo suficientemente sencillo como para que escribamos nuestra propia función cuando los datos se almacenan en un `DataFrame`.\n",
    "\n",
    "Comenzaremos con un ejemplo simple. El conjunto de datos `Portfolio`, incluido en el paquete `ISLP`. El objetivo es estimar la varianza muestral del parámetro $\\alpha$\n",
    "\n",
    "$$\\hat{\\alpha} = \\dfrac{\\hat\\sigma^2_Y - \\hat\\sigma_{XY}}{\\hat\\sigma^2_X+\\hat\\sigma^2_Y-2\\hat\\sigma_{XY}}$$\n",
    "\n",
    "Crearemos una función `alpha_func()`, la cual toma como entrada un dataframe `D` que se asume contiene columnas `X` e `Y`, así como un vector `idx` que indica qué observaciones se utilizarán para estimar $\\alpha$. La función devuelve la estimación de basada en las observaciones seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.895251</td>\n",
       "      <td>-0.234924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.562454</td>\n",
       "      <td>-0.885176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417090</td>\n",
       "      <td>0.271888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.044356</td>\n",
       "      <td>-0.734198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.315568</td>\n",
       "      <td>0.841983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y\n",
       "0 -0.895251 -0.234924\n",
       "1 -1.562454 -0.885176\n",
       "2 -0.417090  0.271888\n",
       "3  1.044356 -0.734198\n",
       "4 -0.315568  0.841983"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "\n",
    "def alpha_func(D, idx):\n",
    "   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "   return ((cov_[1,1] - cov_[0,1]) /\n",
    "           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))\n",
    "\n",
    "Portfolio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función devuelve una estimación de $\\alpha$ a partir de la fórmula de varianza mínima a las observaciones indexadas por el argumento `idx`. Por ejemplo, el siguiente comando estima utilizando las 100 observaciones completas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, seleccionamos aleatoriamente 100 observaciones de `range(100)`, con reemplazo. Esto equivale a construir un nuevo conjunto de datos bootstrap y a recomputar $\\hat\\alpha$ basado en el nuevo conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619004"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "           rng.choice(100,\n",
    "                      100,\n",
    "                      replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proceso puede generalizarse para crear una función sencilla, `boot_SE()`, que calcule el error estándar mediante bootstrap para funciones arbitrarias que reciban únicamente un dataframe como argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,D,n=None,B=1000,seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / (B-1) - B/(B-1)*(first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos esta función para evaluar la precisión de nuestra estimación de $\\alpha$ usando $B=1000$ repeticiones de bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09122739031706444"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                   Portfolio,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este *output* muestra que el estimado de bootstrap para $SE(\\hat\\alpha)$ es $0.0912$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimando la Precisión de un Modelo de Regresión Lineal\n",
    "\n",
    "El enfoque bootstrap puede utilizarse para evaluar la variabilidad de las estimaciones de los coeficientes y de las predicciones de un método de aprendizaje estadístico. Lo utilizaremos para evaluar la variabilidad de las estimaciones de $\\beta_0$​ y $\\beta_1$, el intercepto y la pendiente para el modelo de regresión lineal que utiliza `horsepower` para predecir `mpg` en el conjunto de datos `Auto`. Compararemos las estimaciones obtenidas mediante el bootstrap con aquellas obtenidas utilizando las fórmulas para $SE(\\hat\\beta_0)$ y $SE(\\hat\\beta_1)$.\n",
    "\n",
    "Para utilizar la función `boot_SE()`, debemos escribir una función (su primer argumento) que tome un dataframe `D` y unos índices `idx` como sus únicos argumentos. Sin embargo, aquí queremos aplicar el bootstrap a un modelo de regresión específico, definido por una fórmula de modelo y datos. Mostramos cómo hacer esto en unos pocos pasos sencillos.\n",
    "\n",
    "Comenzamos escribiendo una función genérica `boot_OLS()` para realizar el bootstrap de un modelo de regresión. Usamos la función `clone()` para hacer una copia de la fórmula que puede ser reajustada al nuevo `DataFrame`. Esto significa que cualquier característica derivada, como las definidas por `poly()` (que veremos a continuación), serán reajustadas en el `DataFrame` remuestreado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto no es exactamente lo que se requiere como primer argumento para `boot_SE()`. Los dos primeros argumentos que especifican el modelo no cambiarán durante el proceso de bootstrap, y deseamos mantenerlos fijos. La función `partial()` del módulo functools realiza precisamente esto: toma una función como argumento y congela algunos de sus parámetros, comenzando desde el primero. La utilizamos para congelar los dos primeros argumentos de la fórmula del modelo en `boot_OLS()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_func  = partial(boot_OLS, MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al escribir `hp_func?` se mostrará que tiene dos argumentos, `D` e `idx`. Es una versión de `boot_OLS()` con los dos primeros argumentos congelados y, por lo tanto, es ideal como primer argumento para `boot_SE()`.\n",
    "\n",
    "La función `hp_func()` puede ahora utilizarse para crear estimaciones bootstrap para los términos de intercepto y pendiente mediante el muestreo aleatorio con reemplazo de las observaciones. Primero demostramos su utilidad con 10 muestras bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.12226577, -0.1555926 ],\n",
       "       [37.18648613, -0.13915813],\n",
       "       [37.46989244, -0.14112749],\n",
       "       [38.56723252, -0.14830116],\n",
       "       [38.95495707, -0.15315141],\n",
       "       [39.12563927, -0.15261044],\n",
       "       [38.45763251, -0.14767251],\n",
       "       [38.43372587, -0.15019447],\n",
       "       [37.87581142, -0.1409544 ],\n",
       "       [37.95949036, -0.1451333 ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "np.array([hp_func(Auto,\n",
    "          rng.choice(Auto.index,\n",
    "                     392,\n",
    "                     replace=True)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, utilizamos la función `boot_SE()` para calcular los errores estándar de $1000$ estimaciones bootstrap para los términos de intercepto y pendiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.731542\n",
       "horsepower    0.006095\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_se = boot_SE(hp_func,Auto,B=1000,seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto indica que la estimación bootstrap para $SE(\\hat\\beta_0)$ es $0.73$ y que la estimación bootstrap para $SE(\\hat\\beta_1)$ es $0.0061$. Se pueden utilizar fórmulas estándar para calcular los errores estándar de los coeficientes de regresión en un modelo lineal. Estos se pueden obtener utilizando la función `summarize()` del módulo `ISLP.sm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estimaciones del error estándar para $\\hat\\beta_0$ y $\\hat\\beta_1$ obtenidas utilizando las \"fórmulas\" son $0.717$ para la intersección y $0.006$ para la pendiente. Curiosamente, estas difieren algo de las estimaciones obtenidas mediante el bootstrap. ¿Indica esto un problema con el bootstrap? De hecho, sugiere lo contrario. Recordemos que las fórmulas estándar dadas \n",
    "\n",
    "$$SE(\\hat\\beta_1) = \\dfrac{\\sigma^2}{\\sum\\limits_{i=1}^n(x_i-\\bar{x})}\\text{  y  }SE(\\hat\\beta_0)^2 = \\sigma^2\\left[\\frac{1}{n} + \\dfrac{\\bar{x}^2}{\\sum\\limits_{i=1}^n(x_i-\\bar{x})^2}\\right]$$\n",
    "\n",
    "se basan en ciertas suposiciones. Por ejemplo, dependen del parámetro desconocido $\\sigma^2$, la varianza de $\\varepsilon$. Luego estimamos $\\sigma^2$ utilizando el $RSS$. Aunque la fórmula para los errores estándar no depende de que el modelo lineal sea correcto, la estimación de $\\sigma^2$ sí lo hace. Por ejemplo, si existe una relación no lineal en los datos, los residuos de un ajuste lineal estarán inflados, al igual que $\\sigma^2$. En segundo lugar, las fórmulas estándar asumen (poco realísticamente) que los $x_i$ son fijos y que toda la variabilidad proviene de la variación en los errores $\\varepsilon$. El enfoque bootstrap no depende de ninguna de estas suposiciones, por lo que es probable que proporcione una estimación más precisa de los errores estándar de $\\beta_0$ y $\\beta_1$ que los resultados obtenidos con `sm.OLS`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semMII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
